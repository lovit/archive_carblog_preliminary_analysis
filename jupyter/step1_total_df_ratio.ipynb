{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class SubwordDocumentFrequencyHandler:\n",
    "    def __init__(self, corpus_directory, parameter_fname):\n",
    "        with open(parameter_fname, 'rb') as f:\n",
    "            import pickle\n",
    "            params = pickle.load(f)\n",
    "        self.subword_slot = params['df']\n",
    "        self.index2subword = params['index2subword']\n",
    "        self.subword2index = {word:index for index,word in enumerate(self.index2subword)}\n",
    "        self.corpus_length = self._corpus_length(corpus_directory)\n",
    "        self.num_words, self.num_categories = self.subword_slot.shape\n",
    "        \n",
    "    def _corpus_length(self, corpus_directory):\n",
    "        import glob\n",
    "        files = glob.glob(corpus_directory + '*.txt')\n",
    "        files = sorted(files, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "        \n",
    "        corpus_length = []\n",
    "        for file in files:\n",
    "            with open(corpus_directory+'/'+file, encoding='utf-8') as f:\n",
    "                corpus_length.append(len(f.readlines()))\n",
    "        return corpus_length\n",
    "    \n",
    "    def decode(self,idx):\n",
    "        if 0 <= idx < self.num_words:\n",
    "            return self.index2subword[idx]\n",
    "        return None\n",
    "    \n",
    "    def get_total_df_ratio_from_word(self, word):\n",
    "        idx = self.subword2index.get(word, -1)\n",
    "        return self.get_total_df_ratio_from_word_index(idx)\n",
    "        \n",
    "    def get_total_df_ratio_from_word_index(self, idx):\n",
    "        if idx == -1 : return None\n",
    "        total_freq = [w*l for w,l in zip(self.subword_slot[idx], self.corpus_length)]\n",
    "        return 100*sum(total_freq)/sum(self.corpus_length)\n",
    "    \n",
    "    def total_df_ratio_for_all_words(self):\n",
    "        total_df_ratio = []\n",
    "        for i in range(self.num_words):\n",
    "            print('\\r  computing total df ratio {} / {}'.format(i+1, self.num_words), flush=True, end='')\n",
    "            total_df_ratio.append(self.get_total_df_ratio_from_word_index(i))\n",
    "        print('\\r total df ratio computing was done.        ')\n",
    "        return total_df_ratio\n",
    "        \n",
    "def get_positive_words(positive_corpus,\n",
    "                       positive_total_df_ratio,\n",
    "                       reference_corpus,\n",
    "                       reference_total_df_ratio,\n",
    "                       min_percentage_of_positive_words,\n",
    "                       min_percentage_of_reference_words):\n",
    "    def is_int(word):\n",
    "        try:\n",
    "            word = int(word)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    positive_words = set([w for w, r in zip(positive_corpus.index2subword, positive_total_df_ratio) if r > min_percentage_of_positive_words and not is_int(w)])\n",
    "    reference_words = set([w for w, r in zip(reference_corpus.index2subword, reference_total_df_ratio) if r > min_percentage_of_reference_words and not is_int(w)])\n",
    "    filtered_positive_words = positive_words - reference_words\n",
    "    \n",
    "    return filtered_positive_words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''sample data'''\n",
    "# corpus_directory = '../corpus_norm_sample/'\n",
    "# parameter_fname = '../../DY_GitHub/carblog_positive_document_selection/df.pkl'\n",
    "\n",
    "'''car corpus data directory'''\n",
    "car_corpus_directory = '../corpus_norm/'\n",
    "car_parameter_fname = '../models/subword_df_slot.pkl'\n",
    "\n",
    "'''general corpus data directory'''\n",
    "general_corpus_directory = '../corpus_reference_norm/'\n",
    "general_parameter_fname = '../models_reference/subword_df_slot.pkl'\n",
    "\n",
    "'''define objects'''\n",
    "positive_corpus = YOURNAME(car_corpus_directory, car_parameter_fname)\n",
    "positive_total_df_ratio = positive_corpus.total_df_ratio_for_all_words()\n",
    "\n",
    "reference_corpus = YOURNAME(general_corpus_directory, general_parameter_fname)\n",
    "reference_total_df_ratio = reference_corpus.total_df_ratio_for_all_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_to_categories(directory):\n",
    "    with open(directory, 'r', encoding='utf-8') as f:\n",
    "        categories = f.readlines()\n",
    "        categories = [c.strip() for c in categories]\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category_sensitive_words_list(positive_corpus, index_to_categories, max_average_ratio):\n",
    "    category_sensitive_words = {i:[] for i in range(len(index_to_categories))}\n",
    "    for index, df_dist in enumerate(positive_corpus.subword_slot):\n",
    "        if df_dist.max()/df_dist.mean() > max_average_ratio:\n",
    "            category_index = df_dist.argmax()\n",
    "            word = positive_corpus.decode(index)\n",
    "            category_sensitive_words[category_index].append(word)\n",
    "    category_sensitive_words = [set(words) for c, words in sorted(category_sensitive_words.items())]\n",
    "    return category_sensitive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cars = index_to_categories('../car_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_sensitive_words_list = get_category_sensitive_words_list(positive_corpus=positive_corpus,\n",
    "                                                                index_to_categories=cars,\n",
    "                                                                max_average_ratio=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_car_words = get_positive_words(positive_corpus,\n",
    "                                        positive_total_df_ratio,\n",
    "                                        reference_corpus,\n",
    "                                        reference_total_df_ratio,\n",
    "                                        min_percentage_of_positive_words=3,\n",
    "                                        min_percentage_of_reference_words=2\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_co_occurred(wc, wf, doc):\n",
    "    return 1 if ' '+wc in ' '+doc and ' '+wf in ' '+doc else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_cooccurrence_document_frequency_ratio(category_sensitive_words_list, positive_words, subword2index, corpus_directory):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ----------\n",
    "        category_sensitive_words_list: list of set of str\n",
    "            list[category_index]: [{word, word, ....}, {word, word, ....}, ...]\n",
    "            len(category_sensitive_words_list) is equal number of categories\n",
    "        positive_words: set of str\n",
    "        \n",
    "    Returns:\n",
    "    ----------\n",
    "        list of sparse matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_sparse_matrices = []    \n",
    "    \n",
    "    from collections import defaultdict\n",
    "    \n",
    "    for c, category_sensitive_words in enumerate(category_sensitive_words_list):\n",
    "        wc_occurrence = defaultdict(int) \n",
    "        cooccurrence = defaultdict(lambda: defaultdict(int))\n",
    "        corpus_fname = '{}/{}.txt'.format(corpus_directory, c)\n",
    "\n",
    "        with open(corpus_fname, 'r', encoding='utf-8') as f:\n",
    "            postings = f.readlines()\n",
    "            \n",
    "        process_time = time.time()\n",
    "        for i_wc, wc in enumerate(category_sensitive_words):\n",
    "            filtered_postings = [post for post in postings if wc in post]\n",
    "            for wf in positive_words:     \n",
    "                cooccur = sum([is_co_occurred(wc, wf, post) for post in filtered_postings]) / len(filtered_postings)\n",
    "                cooccurrence[wc][wf] = cooccur\n",
    "            if i_wc == 0:\n",
    "                continue\n",
    "            print('\\r scanned {}/{} category sensitive words'.format(i_wc+1, len(category_sensitive_words)), flush=True, end='')\n",
    "        \n",
    "        process_time = time.time() - process_time\n",
    "        print('\\rcategory = {}, processing time = {}'.format(c, '%.2f sec' % process_time))\n",
    "        \n",
    "        \n",
    "        from scipy.sparse import csr_matrix\n",
    "        row_ind = []\n",
    "        col_ind = []\n",
    "        data = []\n",
    "        for sensitive_word, positive_word_counter in cooccurrence.items():\n",
    "            i = subword2index.get(sensitive_word, -1)\n",
    "            if i == -1:\n",
    "                continue\n",
    "            for positive_word, cooccur in positive_word_counter.items():\n",
    "                j = subword2index.get(positive_word, -1)\n",
    "                if j == -1:\n",
    "                    continue\n",
    "                row_ind.append(i)\n",
    "                col_ind.append(j)\n",
    "                data.append(cooccur)\n",
    "            \n",
    "        csr_matrix((data, (row_ind, col_ind)))\n",
    "    \n",
    "    list_of_sparse_matrices.append(csr_matrix)\n",
    "        \n",
    "    return list_of_sparse_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_sparse_cooccurrence_matrices = calculate_cooccurrence_document_frequency_ratio(category_sensitive_words_list = category_sensitive_words_list,\n",
    "                                                                                       positive_words = filtered_car_words,\n",
    "                                                                                       subword2index = positive_corpus.subword2index,\n",
    "                                                                                       corpus_directory = '../corpus_norm/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
